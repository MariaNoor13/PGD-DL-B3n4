{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# The mathematical building blocks of neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## A first look at a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Loading the MNIST dataset in Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The network architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The compilation step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Preparing the image data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**\"Fitting\" the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 4s 6ms/step - loss: 0.2645 - accuracy: 0.9236\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1078 - accuracy: 0.9683\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0698 - accuracy: 0.9796\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0508 - accuracy: 0.9848\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0381 - accuracy: 0.9884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1704205abe0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the model to make predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 89ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([8.43707415e-09, 1.20773869e-09, 3.20562026e-06, 6.24366794e-06,\n",
       "       1.44976045e-11, 4.69746853e-10, 2.16620081e-12, 9.99989748e-01,\n",
       "       1.07285722e-07, 6.76903710e-07], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digits = test_images[0:10] # 10 iamges taken\n",
    "predictions = model.predict(test_digits)\n",
    "predictions[0]  #1st image probalilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "fig, axes = plt.subplots(1, 10, figsize=(15, 2))  # Adjust figsize as needed\n",
    "\n",
    "for idx, img in enumerate(test_digits):\n",
    "    img_r = img.reshape(28,28)\n",
    "    axes[idx].imshow(img_r, cmap=plt.cm.binary)\n",
    "    axes[idx].axis('off')\n",
    "    pr = np.argmax(predictions[idx])\n",
    "    axes[idx].set_title(str(pr))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Evaluating the model on new data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.0649 - accuracy: 0.9794\n",
      "test_acc: 0.9793999791145325\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"test_acc: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Data representations for neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Scalars (rank-0 tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(12)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Vectors (rank-1 tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  3,  6, 14,  7])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([12, 3, 6, 14, 7])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Matrices (rank-2 tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[5, 78, 2, 34, 0],\n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 36, 2]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Rank-3 and higher-rank tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Key attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Displaying the fourth digit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "digit = train_images[4]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show(img):\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The notion of data batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "batch = train_images[:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "batch = train_images[128:256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "n = 3\n",
    "batch = train_images[128 * n:128 * (n + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Real-world examples of data tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Vector data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Timeseries data or sequence data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Video data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## The gears of neural networks: tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Element-wise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] = max(x[i, j], 0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_add(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert x.shape == y.shape\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[i, j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 0.00 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "x = np.random.random((20, 100))\n",
    "y = np.random.random((20, 100))\n",
    "\n",
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = x + y\n",
    "    z = np.maximum(z, 0.)\n",
    "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "non vector approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 1.46 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = naive_add(x, y)\n",
    "    z = naive_relu(z)\n",
    "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.random.random((32, 10))\n",
    "y = np.random.random((10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "y = np.expand_dims(y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "Y = np.concatenate([y] * 32, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_add_matrix_and_vector(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.random.random((64, 3, 32, 10))\n",
    "y = np.random.random((32, 10))\n",
    "z = np.maximum(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Tensor product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "single dimensional vectors (vectorized dot product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "x = np.random.random((32,))\n",
    "y = np.random.random((32,))\n",
    "z = np.dot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "single dim : non-vactorized naive dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_vector_dot(x, y):\n",
    "    assert len(x.shape) == 1\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    z = 0.\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x is matrix (2 sim), y is vector (1 dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]  # no. of columns in x must equal no. of rows in y\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i] += x[i, j] * y[j]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        z[i] = naive_vector_dot(x[i, :], y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now defining function for naive dot procuct of 2 matrices (both 2 dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_matrix_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 2\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros((x.shape[0], y.shape[1]))\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            row_x = x[i, :]\n",
    "            column_y = y[:, j]\n",
    "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Tensor reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Geometric interpretation of tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A geometric interpretation of deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## The engine of neural networks: gradient-based optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### What's a derivative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Derivative of a tensor operation: the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Chaining derivatives: The Backpropagation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The chain rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Automatic differentiation with computation graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The gradient tape in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1d tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.Variable(0.)  # Create a TensorFlow variable 'x' and initialize with 0.\n",
    "\n",
    "# Define a context manager for automatic differentiation.\n",
    "with tf.GradientTape() as tape: \n",
    "    y = 2 * x + 3  # Define a linear function.\n",
    "\n",
    "# Calculate the gradient of 'y' with respect to 'x'.\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)\n",
    "# Print the calculated gradient.\n",
    "print(grad_of_y_wrt_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2d tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2. 2.]\n",
      " [2. 2.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#similar as sbove except x holds 2 values\n",
    "x = tf.Variable(tf.random.uniform((2, 2)))\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)\n",
    "print(grad_of_y_wrt_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weights update mechanism (internally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "array([[0.93444335, 0.93444335],\n",
      "       [0.76206493, 0.76206493]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 2.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a TensorFlow variable 'W' with random values in a 2x2 matrix.\n",
    "W = tf.Variable(tf.random.uniform((2, 2)))\n",
    "\n",
    "# Define a TensorFlow variable 'b' with zeros in a 2-dimensional vector.\n",
    "b = tf.Variable(tf.zeros((2,)))\n",
    "\n",
    "# Generate a random input data tensor 'x' as a 2x2 matrix. this is feature tensor\n",
    "x = tf.random.uniform((2, 2))\n",
    "\n",
    "# Define a context manager for automatic differentiation.\n",
    "with tf.GradientTape() as tape:\n",
    "    # Calculate the output 'y' using matrix multiplication (matmul) and addition.\n",
    "    y = tf.matmul(x, W) + b\n",
    "\n",
    "# Calculate the gradient of 'y' with respect to both 'W' and 'b'.\n",
    "grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])\n",
    "#print\n",
    "print(grad_of_y_wrt_W_and_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Looking back at our first example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/469 [..............................] - ETA: 2:54 - loss: 2.4114 - accuracy: 0.0703"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2617 - accuracy: 0.9252\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1066 - accuracy: 0.9681\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0705 - accuracy: 0.9794\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0516 - accuracy: 0.9848\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0387 - accuracy: 0.9880\n",
      "CPU times: total: 6.84 s\n",
      "Wall time: 14.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x170473e4eb0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Reimplementing our first example from scratch in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple Dense class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class NaiveDense:\n",
    "    def __init__(self, input_size, output_size, activation):\n",
    "        self.activation = activation\n",
    "\n",
    "        # Initialize the weight matrix W with random values between 0 and 0.1\n",
    "        w_shape = (input_size, output_size)\n",
    "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
    "        self.W = tf.Variable(w_initial_value)\n",
    "\n",
    "        # Initialize the bias vector b with zeros\n",
    "        b_shape = (output_size,)\n",
    "        b_initial_value = tf.zeros(b_shape)\n",
    "        self.b = tf.Variable(b_initial_value)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [self.W, self.b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple Sequential class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class NaiveSequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)  # Apply each layer sequentially\n",
    "        return x\n",
    "\n",
    "    @property  # this decorator acts like a getter method and one can use model.weights to access weight as an attribute\n",
    "    def weights(self):\n",
    "        weights = []\n",
    "        for layer in self.layers:\n",
    "            weights += layer.weights  # Collect weights from each layer\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.09 ms ± 320 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model = NaiveSequential([\n",
    "    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
    "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
    "])\n",
    "assert len(model.weights) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A batch generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class BatchGenerator:\n",
    "    def __init__(self, images, labels, batch_size=128):\n",
    "        \n",
    "        assert len(images) == len(labels)\n",
    "\n",
    "        self.index = 0\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Calculate the total number of batches\n",
    "        self.num_batches = math.ceil(len(images) / batch_size)\n",
    "\n",
    "    def next(self):\n",
    "        # Slice the images and labels for the current batch\n",
    "        images = self.images[self.index : self.index + self.batch_size]\n",
    "        labels = self.labels[self.index : self.index + self.batch_size]\n",
    "\n",
    "        # Increment the index for the next batch\n",
    "        self.index += self.batch_size\n",
    "\n",
    "        return images, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Running one training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def one_training_step(model, images_batch, labels_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images_batch)\n",
    "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(labels_batch, predictions)\n",
    "        average_loss = tf.reduce_mean(per_sample_losses)\n",
    "    \n",
    "    gradients = tape.gradient(average_loss, model.weights)\n",
    "    update_weights(gradients, model.weights)\n",
    "\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating gradients using simple tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "# Define a function to update model weights\n",
    "def update_weights(gradients, weights):\n",
    "    # Iterate over the gradients and weights\n",
    "    for gradient, weight in zip(gradients, weights):\n",
    "        # Update the weight using gradient descent\n",
    "        weight.assign_sub(gradient * learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating gradients using Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Create an instance of the SGD optimizer with a specified learning rate\n",
    "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "# Define a function to update model weights using the optimizer\n",
    "def update_weights(gradients, weights):\n",
    "    # Zip gradients and weights together and apply the updates\n",
    "    optimizer.apply_gradients(zip(gradients, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The full training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#Training loop for a machine learning model using mini-batch stochastic gradient descent.\n",
    "def fit(model, images, labels, epochs, batch_size=128):\n",
    "    # Loop over the specified number of epochs\n",
    "    for epoch_counter in range(epochs):\n",
    "        print(f\"Epoch {epoch_counter}\")\n",
    "        batch_generator = BatchGenerator(images, labels, batch_size)\n",
    "        \n",
    "        # Loop over mini-batches within the epoch\n",
    "        for batch_counter in range(batch_generator.num_batches):\n",
    "            images_batch, labels_batch = batch_generator.next()\n",
    "            loss = one_training_step(model, images_batch, labels_batch)\n",
    "            if batch_counter % 100 == 0:\n",
    "                print(f\"Loss at batch {batch_counter}: {loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Loss at batch 0: 0.03258\n",
      "Loss at batch 100: 0.02386\n",
      "Loss at batch 200: 0.04201\n",
      "Epoch 1\n",
      "Loss at batch 0: 0.03251\n",
      "Loss at batch 100: 0.02386\n",
      "Loss at batch 200: 0.04197\n",
      "Epoch 2\n",
      "Loss at batch 0: 0.03244\n",
      "Loss at batch 100: 0.02385\n",
      "Loss at batch 200: 0.04194\n",
      "Epoch 3\n",
      "Loss at batch 0: 0.03238\n",
      "Loss at batch 100: 0.02385\n",
      "Loss at batch 200: 0.04190\n",
      "Epoch 4\n",
      "Loss at batch 0: 0.03231\n",
      "Loss at batch 100: 0.02384\n",
      "Loss at batch 200: 0.04187\n",
      "Epoch 5\n",
      "Loss at batch 0: 0.03225\n",
      "Loss at batch 100: 0.02384\n",
      "Loss at batch 200: 0.04184\n",
      "Epoch 6\n",
      "Loss at batch 0: 0.03218\n",
      "Loss at batch 100: 0.02383\n",
      "Loss at batch 200: 0.04180\n",
      "Epoch 7\n",
      "Loss at batch 0: 0.03212\n",
      "Loss at batch 100: 0.02383\n",
      "Loss at batch 200: 0.04176\n",
      "Epoch 8\n",
      "Loss at batch 0: 0.03206\n",
      "Loss at batch 100: 0.02382\n",
      "Loss at batch 200: 0.04173\n",
      "Epoch 9\n",
      "Loss at batch 0: 0.03200\n",
      "Loss at batch 100: 0.02382\n",
      "Loss at batch 200: 0.04169\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))  # Reshape images to 1D vectors\n",
    "train_images = train_images.astype(\"float32\") / 255  # Normalize pixel values to [0, 1]\n",
    "test_images = test_images.reshape((10000, 28 * 28))  # Reshape test images\n",
    "test_images = test_images.astype(\"float32\") / 255  # Normalize test images\n",
    "\n",
    "# Call training loop functionl\n",
    "fit(model, train_images, train_labels, epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "predictions = model(test_images)\n",
    "predictions = predictions.numpy()\n",
    "\n",
    "# Find the predicted labels by taking the argmax along axis 1\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Compare the predicted labels with the true test labels to check for matches\n",
    "matches = predicted_labels == test_labels\n",
    "\n",
    "# Calculate and print the accuracy of the model's predictions\n",
    "accuracy = matches.mean()\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter02_mathematical-building-blocks.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
